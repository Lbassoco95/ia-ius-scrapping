#!/usr/bin/env python3
"""
Script para analizar la estructura de la pÃ¡gina de SCJN
"""

import requests
from bs4 import BeautifulSoup
import json

def analyze_scjn_page():
    """Analizar la estructura de la pÃ¡gina de SCJN"""
    print("ğŸ” ANALIZANDO ESTRUCTURA DE LA PÃGINA SCJN")
    print("=" * 50)
    
    try:
        # Obtener pÃ¡gina
        url = "https://sjf2.scjn.gob.mx/busqueda-principal-tesis"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        print(f"âœ… PÃ¡gina obtenida - Status: {response.status_code}")
        print(f"ğŸ“„ TÃ­tulo de la pÃ¡gina: {soup.title.string if soup.title else 'No encontrado'}")
        
        # Buscar elementos que podrÃ­an contener tesis
        print("\nğŸ” Buscando elementos de tesis...")
        
        # Buscar enlaces que contengan "tesis"
        tesis_links = soup.find_all('a', href=lambda x: x and 'tesis' in x.lower())
        print(f"ğŸ“ Enlaces con 'tesis': {len(tesis_links)}")
        
        for i, link in enumerate(tesis_links[:5]):
            print(f"   {i+1}. {link.get('href', 'N/A')} - {link.get_text(strip=True)[:50]}...")
        
        # Buscar tablas
        tables = soup.find_all('table')
        print(f"\nğŸ“Š Tablas encontradas: {len(tables)}")
        
        # Buscar divs con clases especÃ­ficas
        divs = soup.find_all('div', class_=True)
        classes = set()
        for div in divs:
            classes.update(div.get('class', []))
        
        print(f"\nğŸ·ï¸ Clases de divs encontradas: {len(classes)}")
        relevant_classes = [cls for cls in classes if any(keyword in cls.lower() for keyword in ['tesis', 'resultado', 'busqueda', 'item', 'row'])]
        print(f"ğŸ“‹ Clases relevantes: {relevant_classes}")
        
        # Buscar elementos con estas clases
        for cls in relevant_classes:
            elements = soup.find_all(class_=cls)
            print(f"   {cls}: {len(elements)} elementos")
        
        # Buscar elementos con data attributes
        data_elements = soup.find_all(attrs={"data-": True})
        print(f"\nğŸ“Š Elementos con data attributes: {len(data_elements)}")
        
        # Guardar HTML para anÃ¡lisis manual
        with open('data/page_analysis.html', 'w', encoding='utf-8') as f:
            f.write(response.text)
        
        print(f"\nğŸ’¾ HTML guardado en: data/page_analysis.html")
        
        # Buscar patrones especÃ­ficos
        print("\nğŸ” Buscando patrones especÃ­ficos...")
        
        # Buscar nÃºmeros que podrÃ­an ser IDs de tesis
        import re
        numbers = re.findall(r'\d{7,}', response.text)
        unique_numbers = list(set(numbers))
        print(f"ğŸ”¢ NÃºmeros largos encontrados (posibles IDs): {len(unique_numbers)}")
        print(f"   Ejemplos: {unique_numbers[:10]}")
        
        # Buscar texto que contenga "tesis" o "jurisprudencia"
        tesis_text = soup.find_all(text=re.compile(r'tesis|jurisprudencia', re.IGNORECASE))
        print(f"ğŸ“ Texto con 'tesis' o 'jurisprudencia': {len(tesis_text)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error analizando pÃ¡gina: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    analyze_scjn_page() 