#!/usr/bin/env python3
"""
SCRAPER DE PRODUCCI√ìN - SCJN
Sistema completo con descarga de PDFs y subida a Google Drive
"""

import sys
import os
import json
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path

# Agregar src al path
sys.path.insert(0, 'src')

def setup_logging():
    """Configurar logging para producci√≥n"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(f"logs/production_scraper_{datetime.now().strftime('%Y%m%d')}.log"),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def main():
    """Funci√≥n principal del scraper de producci√≥n"""
    logger = setup_logging()
    
    logger.info("üöÄ INICIANDO SCRAPER DE PRODUCCI√ìN")
    logger.info("=" * 60)
    
    try:
        # Importar m√≥dulos necesarios
        from src.scraper.main import ScrapingOrchestrator
        from src.database.models import create_tables, get_session, Tesis
        from src.config import Config
        
        # Verificar configuraci√≥n
        logger.info("üìã Verificando configuraci√≥n...")
        
        # Crear directorios necesarios
        Path("data/pdfs").mkdir(parents=True, exist_ok=True)
        Path("logs").mkdir(exist_ok=True)
        Path("credentials").mkdir(exist_ok=True)
        
        # Verificar Google Drive
        if Config.GOOGLE_DRIVE_ENABLED:
            logger.info("‚úÖ Google Drive habilitado")
            if not Config.GOOGLE_DRIVE_FOLDER_ID:
                logger.warning("‚ö†Ô∏è GOOGLE_DRIVE_FOLDER_ID no configurado")
        else:
            logger.info("‚ÑπÔ∏è Google Drive deshabilitado")
        
        # Crear tablas de base de datos
        logger.info("üóÑÔ∏è Configurando base de datos...")
        create_tables()
        
        # Verificar estado de la base de datos
        session = get_session()
        total_tesis = session.query(Tesis).count()
        logger.info(f"üìä Tesis en base de datos: {total_tesis}")
        
        # Inicializar orquestador
        logger.info("ü§ñ Inicializando orquestador de scraping...")
        orchestrator = ScrapingOrchestrator()
        
        # Configurar par√°metros de producci√≥n
        max_documents = 50  # Documentos por sesi√≥n
        max_hours = 2       # M√°ximo 2 horas por sesi√≥n
        
        logger.info(f"‚öôÔ∏è Configuraci√≥n de producci√≥n:")
        logger.info(f"   - M√°ximo documentos por sesi√≥n: {max_documents}")
        logger.info(f"   - Tiempo m√°ximo por sesi√≥n: {max_hours} horas")
        logger.info(f"   - Descarga de PDFs: HABILITADA")
        logger.info(f"   - Subida a Google Drive: {'HABILITADA' if Config.GOOGLE_DRIVE_ENABLED else 'DESHABILITADA'}")
        
        # Ejecutar scraping completo
        logger.info("üîÑ Iniciando proceso de scraping...")
        start_time = time.time()
        
        orchestrator.run_full_scraping(max_documents=max_documents)
        
        # Mostrar resumen final
        end_time = time.time()
        duration = end_time - start_time
        duration_hours = duration / 3600
        
        logger.info("=" * 60)
        logger.info("üìä RESUMEN DE PRODUCCI√ìN")
        logger.info("=" * 60)
        logger.info(f"‚è±Ô∏è Tiempo total de ejecuci√≥n: {duration_hours:.2f} horas")
        
        # Verificar resultados
        session = get_session()
        tesis_con_pdf = session.query(Tesis).filter(Tesis.google_drive_id.isnot(None)).count()
        total_tesis_final = session.query(Tesis).count()
        
        logger.info(f"üìÑ Total tesis en BD: {total_tesis_final}")
        logger.info(f"üìÅ Tesis con PDF en Drive: {tesis_con_pdf}")
        logger.info(f"üìà Nuevas tesis agregadas: {total_tesis_final - total_tesis}")
        
        if Config.GOOGLE_DRIVE_ENABLED:
            logger.info(f"‚òÅÔ∏è PDFs subidos a Google Drive: {tesis_con_pdf}")
        
        logger.info("‚úÖ SCRAPER DE PRODUCCI√ìN COMPLETADO")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error en scraper de producci√≥n: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
